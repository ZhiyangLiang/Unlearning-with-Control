# RAM

#### GA:

|      | Forget Quality        | Truth Ratio (Forget) | Truth Ratio         | Forget Rate | Normal Rate |
| ---- | --------------------- | -------------------- | ------------------- | ----------- | ----------- |
| -10  | 0.02860307028023343   | 1.1023404297685966   | 0.1772736467493774  | 20/20       | 0/20        |
| -20  | 0.0005039436209702519 | 1.4327552545572773   | 0.18005564074542135 | 20/20       | 0/20        |
| -40  | 0.006760732303569208  | 2.8553399901793375   | 0.2947007497467353  | 20/20       | 0/20        |
| -80  | 0.01430154804770646   | 3.887732111456672    | 0.3120049894604916  | 20/20       | 0/20        |
| -160 | 6.608193292756245e-06 | 3.44895472473839     | 0.28434002940941283 | 20/20       | 0/20        |



##### new

#### GA + Maintain (loss):

|      | Forget Quality        | Truth Ratio (Forget) log(x + 1) | Truth Ratio        | Normal Rate | Memorization(Forget) | Memorization(Retain) |
| ---- | --------------------- | ------------------------------- | ------------------ | ----------- | -------------------- | -------------------- |
| 0    | 0.2656871402817289    | 0.47405271193280124             | 0.5012262371046335 | 100         | 0.0                  | 0.13415354451272243  |
| -0.1 | 0.054141077480362725  | 0.4483399262847587              | 0.5026443906497711 | 100         | 0.25154675           | 0.14753754           |
| -0.2 | 0.02860307028023343   | 0.44991951745197095             | 0.5014390368929675 | 100         | 0.60338542           | 0.13144482           |
| -0.5 | 0.2656871402817289    | 0.48163277007947664             | 0.5019591695387912 | 100         | 0.74558264           | 0.11290228           |
| -1   | 0.16497269950224194   | 0.4880243904700185              | 0.5000810111439259 | 100         | 0.844933             | 0.10967648           |
| -2   | 0.7659314523482239    | 0.6116941510102535              | 0.5021410088687699 | 95          | 0.93870936           | 0.13886587           |
| -5   | 0.09707484379785862   | 0.8600857225251697              | 0.4981400232905985 | 55          | 0.99083279           | 0.17306299           |
| -10  | 0.0003037979589157969 | 1.2578084957188476              | 0.5013366019351407 | 5           | 1.0                  | 0.14037280698368876  |
| -20  | 0.0009013637775216638 | 0.8044638998704501              | 0.5039855802318456 | 0           | 1.0                  | 0.15249401910490087  |
| -50  | 0.01430154804770646   | 1.2290626833544878              | 0.5047030676013443 | 0           | 1.0                  | 0.14157214527980125  |

##### Forget5

|      | Forget Quality          | Truth Ratio (Forget) log(x + 1) | Truth Ratio         | Normal Rate | Memorization(Forget) | Memorization(Retain) |
| ---- | ----------------------- | ------------------------------- | ------------------- | ----------- | -------------------- | -------------------- |
| -0.2 | 0.0002123780052985379,  | 0.47442192331916216             |                     |             |                      |                      |
| -0.5 | 0.00032821228286246976, | 0.48339813848895435             |                     |             |                      |                      |
| -1   | 0.004063647403667497,   | 0.506339001688029               |                     |             |                      |                      |
| -2   | 0.37544716541429346,    | 0.5705230404676174              | 0.49862837162051465 | 90          | 0.8779533460854587   | 0.05064133089133088  |
| -5   | 0.41564933264135784,    | 0.5997664610286438              | 0.5027338763718032  | 0           | 1.0                  | 0.03391369047619048  |
| -10  | 0.0010901071445353942,  | 0.7766398350407538              |                     |             |                      |                      |

##### Forget10

|      | Forget Quality         | Truth Ratio (Forget) log(x + 1) | Truth Ratio        | Normal Rate | Memorization(Forget) | Memorization(Retain) |
| ---- | ---------------------- | ------------------------------- | ------------------ | ----------- | -------------------- | -------------------- |
| -0.2 | 0.0005653711130147049, | 0.46346055403333725             |                    |             |                      |                      |
| -0.5 | 0.005401253888826536,  | 0.48582873030608065             |                    |             |                      |                      |
| -1   | 0.008188327465790023,  | 0.5228767561261815              |                    |             |                      |                      |
| -2   | 0.051784721756374136,  | 0.53697727940306                | 0.5067335141619873 | 90          | 0.9970588235294118   | 0.04589371980676328  |
| -5   | 0.1496667455389953,    | 0.6119360874648334              | 0.5045426599518973 | 0           | 1.0                  | 0.04669811320754717  |
| -10  | 9.65765102754027e-08,  | 0.795023328680022               |                    |             |                      |                      |

##### new

#### GA + Maintain (KL):

|      | Forget Quality        | Truth Ratio (Forget) log(x + 1) | Truth Ratio         | Normal Rate | Memorization(Forget) | Memorization(Retain) |
| ---- | --------------------- | ------------------------------- | ------------------- | ----------- | -------------------- | -------------------- |
| 0    | 0.2656871402817289    | 0.4885062354708063              | 0.4973709781603512  | 100         | 0.0                  | 0.14444742           |
| -0.1 | 0.09707484379785862   | 0.46494258333462013             | 0.4985739218268384  | 100         | 0.26344922           | 0.15493506           |
| -0.2 | 0.2656871402817289    | 0.4688130561649086              | 0.4978173620515449  | 100         | 0.64599348           | 0.16902876           |
| -0.5 | 0.2656871402817289    | 0.4797938597053267              | 0.497506807019728   | 100         | 0.79820703           | 0.18963315           |
| -1   | 0.16497269950224194   | 0.5223227985932011              | 0.4950676188753425  | 95          | 0.85588387           | 0.1906872            |
| -2   | 0.7659314523482239    | 0.56846581698442                | 0.4951186762754217  | 100         | 0.93195293           | 0.16875668           |
| -5   | 0.16497269950224194   | 0.7444440816359535              | 0.48884797672970604 | 20          | 0.99478962           | 0.25199798           |
| -10  | 0.0009013637775216638 | 1.0146658116428677              | 0.49686250453779013 | 0           | 1.0                  | 0.17914435           |
| -20  | 7.17981843959014e-06  | 1.6892665376074167              | 0.49097555360432293 | 0           | 1.0                  | 0.20222248           |
| -50  | 0.003018184077228396  | 1.1897132690040662              | 0.4928759724122157  | 0           | 1.0                  | 0.21008624           |



#### Attention Norm:

|      | Forget Quality        | Truth Ratio (Forget) | Truth Ratio         | Forget Rate | Normal Rate |
| ---- | --------------------- | -------------------- | ------------------- | ----------- | ----------- |
| 0.5  | 0.0005039436209702519 | 1.2032489511538986   | 0.12716979037567844 | 20/20       | 0/20        |
| 0.6  | 0.0012708143485281624 | 1.2114480606876612   | 0.11717358351853763 | 20/20       | 0/20        |
| 0.7  | 0.0012708143485281624 | 1.2150151889810654   | 0.123692225998029   | 20/20       | 0/20        |
| 0.8  | 0.09707484379785862   | 1.1590858680964882   | 0.1699082250334309  | 20/20       | 0/20        |
| 0.9  | 0.0005039436209702519 | 1.3097921282912754   | 0.1742223966649334  | 20/20       | 0/20        |



#### Attention Norm + Maintain (KL):

|      | Forget Quality     | Truth Ratio (Forget) | Truth Ratio         | Forget Rate | Normal Rate |
| ---- | ------------------ | -------------------- | ------------------- | ----------- | ----------- |
| 0.5  | 0.9900193288833089 | 1.0205992870593241   | 0.4811391977859058  | 20/20       | 1/20        |
| 0.6  | 0.7659314523482239 | 0.8920616796517304   | 0.48321068654026883 | 20/20       | 1/20        |
| 0.7  | 0.9900193288833089 | 0.9369876568399166   | 0.49106850889716624 | 20/20       | 6/20        |
| 0.8  | 0.9188052214121167 | 0.8863769343923273   | 0.49106850889716624 | 20/20       | 15/20       |
| 0.9  | 0.7659314523482239 | 0.9020852453629823   | 0.49247677908541293 | 20/20       | 14/20       |



### Main Experiment

##### new

#### opt1.3b-Forget1:

|                | Forget Quality        | Truth Ratio (Forget) log(x + 1) | Truth Ratio         | Normal Rate | Memorization(Forget) | Memorization(Retain) |
| -------------- | --------------------- | ------------------------------- | ------------------- | ----------- | -------------------- | -------------------- |
| Grad ascent    | 6.608193292756245e-06 | 1.7401938648163238              | 0.2991233738250849  | 0.0         | 1.0                  | 1.0                  |
| Grad diff      | 6.608193292756245e-06 | 5.795137125044307               | 0.5096392319945731  | 0.0         | 1.0                  | 0.18896857           |
| KL             | 0.0012708143485281624 | 7.239883032505917               | 0.49749616567040067 | 0.0         | 1.0                  | 0.28461722           |
| DPO            | 0.09707484379785862   | 0.4861505510417829              | 0.4975115276716762  | 1.0         | 0.38311198           | 0.15121509           |
| Attention norm | 0.9188052214121167    | 0.5977584788242771              | 0.5005685610854606  | 0.55        | 0.99618845           | 0.1753412            |

##### new

#### opt1.3b-Forget5:

|                | Forget Quality        | Truth Ratio (Forget) log(x + 1) | Truth Ratio        | Normal Rate | Memorization(Forget) | Memorization(Retain) |
| -------------- | --------------------- | ------------------------------- | ------------------ | ----------- | -------------------- | -------------------- |
| Grad ascent    | 6.608193292756245e-06 | 3.9138867886495623              | 0.3097305511467787 | 0           | 1.0                  | 1.0                  |
| Grad diff      | 2.156357811320459e-05 | 7.427550385099871               | 0.5136199555296264 | 0           | 1.0                  | 0.1624547680142438   |
| KL             | 6.608193292756245e-06 | 6.840719178269473               | 0.5119459650512259 | 0           | 1.0                  | 0.20134147939396296  |
| DPO            | 0.16497269950224194   | 0.4873347480687707              | 0.4997235016052767 | 100         | 0.36522844753101424  | 0.060823412698412696 |
| Attention norm |                       |                                 |                    |             |                      |                      |

##### new

#### opt1.3b-Forget10:

|                | Forget Quality          | Truth Ratio (Forget) log(x + 1) | Truth Ratio        | Normal Rate | Memorization(Forget) | Memorization(Retain) |
| -------------- | ----------------------- | ------------------------------- | ------------------ | ----------- | -------------------- | -------------------- |
| Grad ascent    | 6.608193292756245e-06,  | 6.256475182003747               | 0.3635433423325127 | 0           | 1.0                  | 1.0                  |
| Grad diff      | 2.156357811320459e-05   | 9.046776613276148               | 0.5175673596125493 | 0           | 1.0                  | 0.19303270200544137  |
| KL             | 1.8880552265017844e-06, | 4.812316890031326               | 0.5095369809955987 | 0           | 1.0                  | 0.2626422035354129   |
| DPO            | 0.054141077480362725,   | 0.49259131599049194             | 0.5007024914882593 | 100         | 0.5017301816743882   | 0.037091078855784734 |
| Attention norm |                         |                                 |                    |             |                      |                      |

##### new

#### opt2.7b-Forget1:

|                | Forget Quality         | Truth Ratio (Forget) log(x + 1) | Truth Ratio         | Normal Rate | Memorization(Forget) | Memorization(Retain) |
| -------------- | ---------------------- | ------------------------------- | ------------------- | ----------- | -------------------- | -------------------- |
| Grad ascent    | 2.156357811320459e-05, | 10.534430989032222              | 0.36089260052924305 | 0           | 1.0                  | 1.0                  |
| Grad diff      | 0.0005039436209702519, | 4.953902747360885               | 0.5190663668790896  | 0           | 1.0                  | 0.07679458138760466  |
| KL             | 0.0005039436209702519, | 2.551854868626252               | 0.4970161813418871  | 0           | 1.0                  | 0.13413475054109428  |
| DPO            | 0.006760732303569208,  | 0.488046304177835               | 0.5202190767930981  | 100         | 0.3199578034492441   | 0.10039716332055042  |
| Attention norm |                        |                                 |                     |             |                      |                      |

##### new

#### opt2.7b-Forget5:

|                | Forget Quality          | Truth Ratio (Forget) log(x + 1) | Truth Ratio        | Normal Rate | Memorization(Forget) | Memorization(Retain) |
| -------------- | ----------------------- | ------------------------------- | ------------------ | ----------- | -------------------- | -------------------- |
| Grad ascent    | 1.8632317139826657e-09, | 7.300081577293934               | 0.3330703249369434 | 0           | 1.0                  | 1.0                  |
| Grad diff      | 2.8001701465082902e-09, | 5.470042181363281               | 0.5236240747279708 | 0           | 1.0                  | 0.06336336336336337  |
| KL             | 4.187654526634338e-09,  | 6.068362964005035               | 0.5244877244093739 | 0           | 1.0                  | 0.08138457825957826  |
| DPO            | 0.0005366185447427601,  | 0.47758688351620826             | 0.5211182157391696 | 100         | 0.14851103263417167  | 0.022756410256410255 |
| Attention norm |                         |                                 |                    |             |                      |                      |

##### new

#### opt2.7b-Forget10:

|                | Forget Quality         | Truth Ratio (Forget) log(x + 1) | Truth Ratio | Normal Rate | Memorization(Forget) | Memorization(Retain) |
| -------------- | ---------------------- | ------------------------------- | ----------- | ----------- | -------------------- | -------------------- |
| Grad ascent    | 1.9373085164949765e-12 | 7.744350299031034               |             |             |                      |                      |
| Grad diff      | 1.4988428916097404e-12 | 9.06263837716665                |             |             |                      |                      |
| KL             | 1.1577936224716675e-12 | 25.782738126336984              |             |             |                      |                      |
| DPO            | 0.0001076362675415452  | 0.5157196333082469              |             |             |                      |                      |
| Attention norm |                        |                                 |             |             |                      |                      |

#### llama2_7b-Forget1:

|                | Forget Quality       | Truth Ratio (Forget) | Truth Ratio         | Model Utility      |
| -------------- | -------------------- | -------------------- | ------------------- | ------------------ |
| Grad ascent    | 0.006760732303569208 | 2493.2828007935254   | 0.36495726495726496 | 0.0                |
| Grad diff      | 0.006760732303569208 | 833.2194824650753    | 0.48043812218489534 | 0.7890490202361556 |
| KL             | 0.054141077480362725 | 557.1152863246647    | 0.4894245938531814  | 0.8067523124095978 |
| DPO            | 0.16497269950224194  | 0.6800770514882103   | 0.47154704501362105 | 0.8058486427102942 |
| Attention norm | 0.2656871402817289   | 0.6496588205736173   | 0.4845839034038423  | 0.8194294458831074 |

#### llama2_7b-Forget5:

|                | Forget Quality        | Truth Ratio (Forget) | Truth Ratio         | Model Utility      |
| -------------- | --------------------- | -------------------- | ------------------- | ------------------ |
| Grad ascent    | 5.015146695395365e-07 | 2327489.3456734987   | 0.3451909863467871  | 0.0                |
| Grad diff      | 6.5768913245274e-05   | 1135000.8427289345   | 0.4681945111835357  | 0.7769353869006584 |
| KL             | 0.003018184077228396  | 9826.224557280086    | 0.46804353291814665 | 0.7856765678595893 |
| DPO            | 0.02860307028023343   | 0.6525200828626316   | 0.48251216492417526 | 0.811655007917117  |
| Attention norm | 0.054141077480362725  | 0.6231995308231336   | 0.4840657281134696  | 0.8123089576388699 |

#### llama2_7b-Forget10:

|                | Forget Quality        | Truth Ratio (Forget) | Truth Ratio         | Model Utility      |
| -------------- | --------------------- | -------------------- | ------------------- | ------------------ |
| Grad ascent    | 0.0005039436209702519 | 42253.46977439649    | 0.32095514641924267 | 0.0                |
| Grad diff      | 6.608193292756245e-06 | 219394226000544.66   | 0.48092701902609236 | 0.7882184537219653 |
| KL             | 0.0012708143485281624 | 184584.45261971888   | 0.4768924013431035  | 0.7796800385427977 |
| DPO            | 0.006760732303569208  | 0.6632501657999809   | 0.4818920493986971  | 0.8059224458202804 |
| Attention norm | 0.006760732303569208  | 0.6457157359223038   | 0.47634308941634496 | 0.8135099989902231 |
